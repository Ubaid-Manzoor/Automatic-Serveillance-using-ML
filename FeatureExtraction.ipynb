{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureExtraction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOoBcXE9U4bzTy3uZkIKGtX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ubaid-Manzoor/Automatic-Serveillance-using-ML/blob/master/FeatureExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnEWWVMz9tTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, models, transforms \n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "  print(\"Using gpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUAhN4RK-B-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(model_type=\"vgg16\"):\n",
        "  if model_type == \"vgg16\":\n",
        "    model = models.vgg16(pretrained=True,progress=True)\n",
        "    return model.features\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "  frame = np.reshape(frame,(frame.shape[2],frame.shape[0],frame.shape[1]))\n",
        "  preprocess = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "  return preprocess(transforms.functional.to_pil_image(frame)).unsqueeze(0)\n",
        "\n",
        "  \n",
        "\n",
        "def get_features(frame):\n",
        "  vgg_model = load_model()\n",
        "  processed_frame = preprocess_frame(frame)\n",
        "  vgg_model.eval()\n",
        "  features = vgg_model(processed_frame)\n",
        "  return torch.flatten(features)\n",
        "\n",
        "\n",
        "def save_features(features, path_to_save, frame_no):\n",
        "  torch.save(features,os.path.join(path_to_save,str(frame_no)+\".pt\"))\n",
        "\n",
        "def get_frame_to_take(total_frames,frames_to_take=500):\n",
        "  frames_taken = np.array([])\n",
        "\n",
        "  if total_frames < frames_to_take:\n",
        "    return np.array(list(range(total_frames)))\n",
        "\n",
        "  for i in range(0,total_frames):\n",
        "    if(i%int(total_frames/frames_to_take) == 0):\n",
        "      frames_taken = np.append(frames_taken,i)\n",
        "\n",
        "  \n",
        "  frames_to_remove = np.array([])\n",
        "  frames_to_remove = frames_to_remove.astype('int32')\n",
        "  \n",
        "  for i in range(len(frames_taken)):\n",
        "    if len(frames_to_remove) == (len(frames_taken) - frames_to_take):\n",
        "      break\n",
        "    if i%2 == 0:\n",
        "      frames_to_remove = np.append(frames_to_remove,i)\n",
        "    if len(frames_to_remove) == (len(frames_taken) - frames_to_take):\n",
        "      break\n",
        "    if (len(frames_taken) - i)%2 == 0:\n",
        "      frames_to_remove = np.append(frames_to_remove,len(frames_taken) - i - 1)\n",
        "  \n",
        "  return set(np.delete(frames_taken,frames_to_remove))\n",
        "\n",
        "def yeildframe(videopath):\n",
        "  video = cv2.VideoCapture(videopath)\n",
        "\n",
        "  frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  frames_to_take = get_frame_to_take(frame_count)\n",
        "  \n",
        "  count = 0;success = True;first=True\n",
        "  while success:\n",
        "    success,frame = video.read()\n",
        "    if success and count in frames_to_take:\n",
        "      yield frame\n",
        "    count += 1\n",
        "\n",
        "\n",
        "def filterfolders(paths,folder_to_exclude=[]):\n",
        "  return [path for path in paths \\\n",
        "                    if os.path.isdir(path) \\\n",
        "                        and \\\n",
        "                      path.split('/')[-1] not in folder_to_exclude ]\n",
        "\n",
        "def filterfiles(paths):\n",
        "  return [path for path in paths \\\n",
        "                    if os.path.isfile(path)]\n",
        "\n",
        "def getfullpath(base_path,folders):\n",
        "  return [os.path.join(base_path, folder) for folder in folders]\n",
        "\n",
        "def convert_videoFrame_to_feature(path):\n",
        "  datafolder = filterfolders(getfullpath(path,os.listdir(path)),[\"train\",\".ipynb_checkpoints\"])\n",
        "  os.makedirs(os.path.join(path,\"features\"),exist_ok=True)\n",
        "  \n",
        "  for classfolder in datafolder:\n",
        "    class_name = classfolder.split('/')[-1]\n",
        "    os.makedirs(os.path.join(path,\"features\",class_name),exist_ok=True)\n",
        "    videopaths = getfullpath(classfolder,os.listdir(classfolder))\n",
        "    \n",
        "    for video in videopaths:\n",
        "      video_name = video.split('/')[-1]\n",
        "      os.makedirs(os.path.join(path,\"features\", class_name,video_name),exist_ok=True)\n",
        "\n",
        "      for frame_no,frame in  enumerate(yeildframe(video)):\n",
        "        frame_features = get_features(frame)\n",
        "        save_features(frame_features,os.path.join(path,\"features\", class_name,video_name),frame_no)\n",
        "      print(video.split('/')[-1], \" Compeleted!!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAJj7yHy-B8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/AutomaticServaliance Project/Data/Anomaly-Videos-Part-1'\n",
        "convert_videoFrame_to_feature(path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}