{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutomaticServaliance.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1pc1E8e7nV14xj3IoyXBcT-MZYTM8pafj",
      "authorship_tag": "ABX9TyPgB4PyOECXR1gwfTL8SX0/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d4b8ef53b6f4f9ea163ab5f10564f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a4cf4b744fb0483ba885f5bb4e4b01f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_98507606d49c4970b0a778f3f6f34102",
              "IPY_MODEL_bd200610aa974f40a21f8dbca92bed75"
            ]
          }
        },
        "a4cf4b744fb0483ba885f5bb4e4b01f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98507606d49c4970b0a778f3f6f34102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60e07db134af4a368d75b957c3d1100c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6272044173,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6272044173,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_811381c39cd941b0b87556a8bd43dd63"
          }
        },
        "bd200610aa974f40a21f8dbca92bed75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e81f764893564d8c908940ee4e5ecfcd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.84G/5.84G [57:58&lt;00:00, 1.80MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_405a50445d6545d8b141114d19dd46f4"
          }
        },
        "60e07db134af4a368d75b957c3d1100c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "811381c39cd941b0b87556a8bd43dd63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e81f764893564d8c908940ee4e5ecfcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "405a50445d6545d8b141114d19dd46f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ubaid-Manzoor/Automatic-Serveillance-using-ML/blob/master/AutomaticServaliance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKCa4hI9VuC3",
        "colab_type": "text"
      },
      "source": [
        "NOTE:- THIS CODE WAS RUNNED ON GOOGLE COLAB, THERE ARE THING WHICH WONT RUN IN SOME COMPUTER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBKJyyvtPiy-",
        "colab_type": "text"
      },
      "source": [
        "# Import all Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yMCP2suI9pM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c10aa63d-b0dc-4ca0-84c7-8afc1ad4e139"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import torch.optim as optiom\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, models, transforms \n",
        "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "  print(\"Using gpu\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using gpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH7Q8ex7PpOe",
        "colab_type": "text"
      },
      "source": [
        "# Downloading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI-UjujES-pP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ed0a58c2-9491-4351-f78d-bdb7fb9a313e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J5qZ28SUrS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################################\n",
        "########################################################################\n",
        "###################### SOME USEFUL FUNCTIONS ###########################\n",
        "########################################################################\n",
        "########################################################################\n",
        "import zipfile\n",
        "\n",
        "def removedir(path):\n",
        "  \"\"\"Remove all file and directory recursively\"\"\"\n",
        "  if(os.path.isfile(path)):\n",
        "    os.remove(path)\n",
        "  elif( os.path.isdir(path) ):\n",
        "    path_list = os.listdir(path)\n",
        "    for path_ in path_list:\n",
        "      removedir(os.path.join(path,path_) )\n",
        "    os.rmdir(path)\n",
        "\n",
        "def unzip(path, dest):\n",
        "  with zipfile.ZipFile(path, 'r') as file_to_zip:\n",
        "    file_to_zip.extractall(dest)\n",
        "\n",
        "\n",
        "########################################################################\n",
        "########################################################################\n",
        "########################################################################"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upA1GYI9QBgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "7d4b8ef53b6f4f9ea163ab5f10564f27",
            "a4cf4b744fb0483ba885f5bb4e4b01f2",
            "98507606d49c4970b0a778f3f6f34102",
            "bd200610aa974f40a21f8dbca92bed75",
            "60e07db134af4a368d75b957c3d1100c",
            "811381c39cd941b0b87556a8bd43dd63",
            "e81f764893564d8c908940ee4e5ecfcd",
            "405a50445d6545d8b141114d19dd46f4"
          ]
        },
        "outputId": "24f546a4-ba77-417c-9975-47c832d62ab9"
      },
      "source": [
        "#################### Download and Unziping the Dataset ############\n",
        "from torch.hub import download_url_to_file\n",
        "\n",
        "url = 'https://uca99ec3038c3fcdd6df2668dc1b.dl.dropboxusercontent.com/cd/0/get/A5ZKwNLPDmodhwYEmwu_IQRSkPJQs9qKvoxQQ5lhqKe9TjoTZ_o1TTFD7n2Cv3Qn4EC5Jd9v_9-ZXhLxIgLh1Kur7dnQedFvdBtUQvnkeAwJoQ/file?_download_id=8495528592147592612394157372631981580157083575271750206206115965&_notify_domain=www.dropbox.com&dl=1'\n",
        "path = \"/content/drive/My Drive/AutomaticServaliance Project/Data\"\n",
        "download_url_to_file(url,path)\n",
        "\n",
        "# file = \"/content/drive/My Drive/AutomaticServaliance Project/\"\n",
        "# unzip(file,path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d4b8ef53b6f4f9ea163ab5f10564f27",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6272044173.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCIJZkMCUXEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = \"/content/drive/My Drive/AutomaticServaliance Project/Data/tmprv1i177x\"\n",
        "unzip(file,path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq-QU-mPQBvX",
        "colab_type": "text"
      },
      "source": [
        "# Transforming the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6un5q6vZI9ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN = 'train'\n",
        "VAL = 'val'\n",
        "TEST = 'test'\n",
        "\n",
        "\n",
        "data_transforms = {\n",
        "    TRAIN: transforms.Compose([\n",
        "                               transforms.ToTensor()\n",
        "    ]),\n",
        "    VAL: transforms.Compose([\n",
        "                             transforms.ToTensor()\n",
        "    ]),\n",
        "    TEST: transforms.Compose([\n",
        "                              transforms.ToTensor()\n",
        "    ])\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmioEZZrPTwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VideoDataset(IterableDataset):\n",
        "  def __init__(self,path,type='train'):\n",
        "    self.path = path \n",
        "    self.train_file = path + '/' + 'train.txt'\n",
        "    self.validation_file = path + '/' + 'validation.txt'\n",
        "    self.type = type\n",
        "    self.train_per = 70\n",
        "  \n",
        "\n",
        "  def pathLists(self,path):\n",
        "    \"\"\" Return List of All the paths(Full) of the videos \"\"\"\n",
        "    pathlist = []\n",
        "\n",
        "    for dirname in os.listdir(path):\n",
        "      if os.path.isdir(path + '/' + dirname):\n",
        "        full_path = [path + '/' + dirname + '/' + filename for filename in os.listdir(path + '/' + dirname)]\n",
        "        pathlist.append(full_path)\n",
        "    return np.array(pathlist)\n",
        "\n",
        "  def read_video(self,path):\n",
        "    vid_cap = cv2.VideoCapture(path)\n",
        "    success, frame = vid_cap.read()\n",
        "    video_tensor = torch.tensor(frame).unsqueeze(3)\n",
        "\n",
        "    count = 0\n",
        "    while success:\n",
        "      success,frame = vid_cap.read()\n",
        "      if success and count%10 == 0:\n",
        "        video_tensor = torch.cat((video_tensor,torch.tensor(frame).unsqueeze(3)),3)\n",
        "      count += 1\n",
        "    return video_tensor\n",
        "\n",
        "  def parse_file(self):\n",
        "    \"\"\" Yeild a Video from the data \"\"\"\n",
        "    if self.type == 'train':\n",
        "      if not os.path.exists(self.train_file):\n",
        "        with open(self.train_file,'w') as file:\n",
        "          for fileList in self.pathLists(path):\n",
        "            for line in fileList[0:math.floor((len(fileList)/100) * self.train_per)]:\n",
        "              file.writelines(line+'\\n')\n",
        "      if os.path.exists(self.train_file) and os.stat(self.train_file).st_size > 0:\n",
        "        with open(self.train_file) as file:\n",
        "          for video_path in file:\n",
        "            yield self.read_video(video_path[:-1])\n",
        "\n",
        "    elif self.type == 'validation': \n",
        "      if not os.path.exists(self.validation_file):\n",
        "        with open(self.validation_file,'w') as file:\n",
        "          for fileList in self.pathLists(path):\n",
        "            for line in fileList[math.floor((len(fileList)/100) * self.train_per):]:\n",
        "              file.writelines(line+'\\n')  \n",
        "      if os.path.exists(self.validation_file) and os.stat(self.validation_file).st_size > 0:\n",
        "        with open(self.validation_file) as file:\n",
        "          for video_path in file:\n",
        "            yield self.read_video(video_path[:-1])\n",
        "       \n",
        "  def __iter__(self):\n",
        "    return iter(self.parse_file())\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHJlC-DidhHu",
        "colab_type": "text"
      },
      "source": [
        "## Convert Frame Into Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ6SsevNdJe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(model_type=\"vgg16\"):\n",
        "  if model_type == \"vgg16\":\n",
        "    model = models.vgg16(pretrained=True,progress=True)\n",
        "    return model.features\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "  frame = np.reshape(frame,(frame.shape[2],frame.shape[0],frame.shape[1]))\n",
        "  preprocess = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "  return preprocess(transforms.functional.to_pil_image(frame)).unsqueeze(0)\n",
        "\n",
        "  \n",
        "\n",
        "def get_features(frame):\n",
        "  vgg_model = load_model()\n",
        "  processed_frame = preprocess_frame(frame)\n",
        "  vgg_model.eval()\n",
        "  features = vgg_model(processed_frame)\n",
        "  return torch.flatten(features)\n",
        "\n",
        "\n",
        "def save_features(features, path_to_save, frame_no):\n",
        "  torch.save(features,os.path.join(path_to_save,str(frame_no)+\".pt\"))\n",
        "\n",
        "def get_frame_to_take(total_frames,frames_to_take=500):\n",
        "  frames_taken = np.array([])\n",
        "\n",
        "  if total_frames < frames_to_take:\n",
        "    return np.array(list(range(total_frames)))\n",
        "\n",
        "  for i in range(0,total_frames):\n",
        "    if(i%int(total_frames/frames_to_take) == 0):\n",
        "      frames_taken = np.append(frames_taken,i)\n",
        "\n",
        "  \n",
        "  frames_to_remove = np.array([])\n",
        "  frames_to_remove = frames_to_remove.astype('int32')\n",
        "  \n",
        "  for i in range(len(frames_taken)):\n",
        "    if len(frames_to_remove) == (len(frames_taken) - frames_to_take):\n",
        "      break\n",
        "    if i%2 == 0:\n",
        "      frames_to_remove = np.append(frames_to_remove,i)\n",
        "    if len(frames_to_remove) == (len(frames_taken) - frames_to_take):\n",
        "      break\n",
        "    if (len(frames_taken) - i)%2 == 0:\n",
        "      frames_to_remove = np.append(frames_to_remove,len(frames_taken) - i - 1)\n",
        "  \n",
        "  return set(np.delete(frames_taken,frames_to_remove))\n",
        "\n",
        "def yeildframe(videopath):\n",
        "  video = cv2.VideoCapture(videopath)\n",
        "\n",
        "  frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  frames_to_take = get_frame_to_take(frame_count)\n",
        "  \n",
        "  count = 0;success = True;first=True\n",
        "  while success:\n",
        "    success,frame = video.read()\n",
        "    if success and count in frames_to_take:\n",
        "      yield frame\n",
        "    count += 1\n",
        "\n",
        "\n",
        "def filterfolders(paths,folder_to_exclude=[]):\n",
        "  return [path for path in paths \\\n",
        "                    if os.path.isdir(path) \\\n",
        "                        and \\\n",
        "                      path.split('/')[-1] not in folder_to_exclude ]\n",
        "\n",
        "def filterfiles(paths):\n",
        "  return [path for path in paths \\\n",
        "                    if os.path.isfile(path)]\n",
        "\n",
        "def getfullpath(base_path,folders):\n",
        "  return [os.path.join(base_path, folder) for folder in folders]\n",
        "\n",
        "def convert_videoFrame_to_feature(path):\n",
        "  datafolder = filterfolders(getfullpath(path,os.listdir(path)),[\"train\",\".ipynb_checkpoints\"])\n",
        "  os.makedirs(os.path.join(path,\"features\"),exist_ok=True)\n",
        "  \n",
        "  for classfolder in datafolder:\n",
        "    class_name = classfolder.split('/')[-1]\n",
        "    os.makedirs(os.path.join(path,\"features\",class_name),exist_ok=True)\n",
        "    videopaths = getfullpath(classfolder,os.listdir(classfolder))\n",
        "    \n",
        "    for video in videopaths:\n",
        "      video_name = video.split('/')[-1]\n",
        "      os.makedirs(os.path.join(path,\"features\", class_name,video_name),exist_ok=True)\n",
        "\n",
        "      for frame_no,frame in  enumerate(yeildframe(video)):\n",
        "        frame_features = get_features(frame)\n",
        "        save_features(frame_features,os.path.join(path,\"features\", class_name,video_name),frame_no)\n",
        "      print(video.split('/')[-1], \" Compeleted!!!\")"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gm-r5SCekFg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "fded496b-badf-4a30-c248-7221246aa484"
      },
      "source": [
        "path = '/content/drive/My Drive/AutomaticServaliance Project/Data/Anomaly-Videos-Part-1'\n",
        "convert_videoFrame_to_feature(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Abuse041_x264.mp4  Compeleted!!!\n",
            "Abuse037_x264.mp4  Compeleted!!!\n",
            "Abuse012_x264.mp4  Compeleted!!!\n",
            "Abuse001_x264.mp4  Compeleted!!!\n",
            "Abuse048_x264.mp4  Compeleted!!!\n",
            "Abuse003_x264.mp4  Compeleted!!!\n",
            "Abuse006_x264.mp4  Compeleted!!!\n",
            "Abuse020_x264.mp4  Compeleted!!!\n",
            "Abuse018_x264.mp4  Compeleted!!!\n",
            "Abuse025_x264.mp4  Compeleted!!!\n",
            "Abuse029_x264.mp4  Compeleted!!!\n",
            "Abuse042_x264.mp4  Compeleted!!!\n",
            "Abuse032_x264.mp4  Compeleted!!!\n",
            "Abuse045_x264.mp4  Compeleted!!!\n",
            "Abuse049_x264.mp4  Compeleted!!!\n",
            "Abuse026_x264.mp4  Compeleted!!!\n",
            "Abuse044_x264.mp4  Compeleted!!!\n",
            "Abuse031_x264.mp4  Compeleted!!!\n",
            "Abuse005_x264.mp4  Compeleted!!!\n",
            "Abuse015_x264.mp4  Compeleted!!!\n",
            "Abuse038_x264.mp4  Compeleted!!!\n",
            "Abuse033_x264.mp4  Compeleted!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VVrd_xAMOER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### If This dataset is use we cant use Shuffle\n",
        "\n",
        "\n",
        "class ImageDataset(IterableDataset):\n",
        "  def __init__(self,path,type='train'):\n",
        "    self.path = path \n",
        "    self.train_file = path + '/' + 'train.txt'\n",
        "    self.validation_file = path + '/' + 'validation.txt'\n",
        "    self.type = type\n",
        "    self.train_per = 70\n",
        "  \n",
        "\n",
        "  def pathLists(self,path):\n",
        "    \"\"\" Return List of All the paths(Full) of the videos \"\"\"\n",
        "    pathlist = []\n",
        "\n",
        "    for dirname in os.listdir(path):\n",
        "      if os.path.isdir(path + '/' + dirname):\n",
        "        full_path = [path + '/' + dirname + '/' + filename for filename in os.listdir(path + '/' + dirname)]\n",
        "        pathlist.append(full_path)\n",
        "    return np.array(pathlist)\n",
        "\n",
        "  def read_video(self,path):\n",
        "    vid_cap = cv2.VideoCapture(path)\n",
        "    success, frame = vid_cap.read()\n",
        "\n",
        "    count = 0\n",
        "    while success:\n",
        "      if success and count%10 == 0:\n",
        "        yield torch.tensor(frame)\n",
        "      success,frame = vid_cap.read()\n",
        "      count += 1\n",
        "\n",
        "  def parse_file(self):\n",
        "    \"\"\" Yeild a Video from the data \"\"\"\n",
        "    if self.type == 'train':\n",
        "      if not os.path.exists(self.train_file):\n",
        "        with open(self.train_file,'w') as file:\n",
        "          for fileList in self.pathLists(path):\n",
        "            for line in fileList[0:math.floor((len(fileList)/100) * self.train_per)]:\n",
        "              file.writelines(line+'\\n')\n",
        "      if os.path.exists(self.train_file) and os.stat(self.train_file).st_size > 0:\n",
        "        with open(self.train_file) as file:\n",
        "          for video_path in file:\n",
        "            for image in self.read_video(video_path[:-1]):\n",
        "              yield image\n",
        "\n",
        "    elif self.type == 'validation': \n",
        "      if not os.path.exists(self.validation_file):\n",
        "        with open(self.validation_file,'w') as file:\n",
        "          for fileList in self.pathLists(path):\n",
        "            for line in fileList[math.floor((len(fileList)/100) * self.train_per):]:\n",
        "              file.writelines(line+'\\n')  \n",
        "      # if os.path.exists(self.validation_file) and os.stat(self.validation_file).st_size > 0:\n",
        "      #   with open(self.validation_file) as file:\n",
        "      #     for video_path in file:\n",
        "      #       for image in read_video(video_path[:-1]):\n",
        "      #         yield image\n",
        "       \n",
        "  def __iter__(self):\n",
        "    return iter(self.parse_file())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGHlVmsukjCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/AutomaticServaliance Project/Data/Anomaly-Videos-Part-1'\n",
        "dataset = ImageDataset(path,type='validation')\n",
        "dataloader = DataLoader(dataset,batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIdpNazsFGRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for data in dataloader:\n",
        "  # print(data.shape)\n",
        "  for image in data:\n",
        "    plt.imshow(image)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6DSwyGmYx1i",
        "colab_type": "text"
      },
      "source": [
        "## Need to extract Image from the Video and Save them according to their Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnuDQya6eZA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_video(path, start_per=15, end_per=85,stride=10):\n",
        "  video = cv2.VideoCapture(path)\n",
        "\n",
        "  frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  frame_rate = int(video.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "  if( (frame_count/frame_rate)/60 > 5 ):\n",
        "    stride = 20\n",
        "  elif( (frame_count/frame_rate)/60 > 10 ):\n",
        "    stride = 30\n",
        "  starting_frame = math.floor((frame_count/100) * start_per)\n",
        "  ending_frame = math.floor((frame_count)/100 * end_per)\n",
        "\n",
        "  print(\"total frames : \",frame_count)\n",
        "  print(\"total image : \",(ending_frame - starting_frame) / stride )\n",
        "  frame_num = 0\n",
        "  success = True\n",
        "  while success:\n",
        "    success,frame = video.read()\n",
        "    frame_num += 1\n",
        "    if success and (frame_num%stride) == 0:\n",
        "      yield np.array(frame)\n",
        "\n",
        "def extract_and_save_Images(paths_file, path_to_store=\"\",folder_name=\"\",extension='.jpg'):\n",
        "  try:\n",
        "    with open(paths_file) as file:\n",
        "      paths = file.readlines()\n",
        "      image_number = 0\n",
        "      for video_path in paths:\n",
        "        image_class = video_path.split('/')[-2]\n",
        "        folder_path = os.path.join(path_to_store , folder_name , image_class )\n",
        "        os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "        for image in extract_video(video_path[:-1]):\n",
        "          try:\n",
        "            cv2.imwrite(os.path.join(folder_path,image_class + '_' + str(image_number) + extension),image)\n",
        "            image_number += 1\n",
        "          except FileNotFoundError:\n",
        "            print(f\"{path_to_store} does not exists\")\n",
        "  except FileNotFoundError:\n",
        "    print(f\"{paths_file} does not exists\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFD6s_W7ThyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paths_file = \"/content/drive/My Drive/AutomaticServaliance Project/Data/Anomaly-Videos-Part-1/train.txt\"\n",
        "extract_and_save_Images(paths_file,os.path.abspath(os.path.join(paths_file,'..')),\"train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeXBIdkKkQt3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12301711-3ced-416b-9d31-ef7af2aec619"
      },
      "source": [
        "path = \"/content/drive/My Drive/AutomaticServaliance Project/Data/Anomaly-Videos-Part-1/train/Assault\"\n",
        "print(len(os.listdir(path)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8331\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUN84Vl2PX1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}